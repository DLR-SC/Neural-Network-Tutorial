{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-06 12:52:42--  https://github.com/DLR-SC/Neural-Network-Tutorial/raw/master/data/nn_theta_check.npy\n",
      "Resolving github.com (github.com)... 140.82.118.3\n",
      "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/DLR-SC/Neural-Network-Tutorial/master/data/nn_theta_check.npy [following]\n",
      "--2019-06-06 12:52:43--  https://raw.githubusercontent.com/DLR-SC/Neural-Network-Tutorial/master/data/nn_theta_check.npy\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 159160 (155K) [application/octet-stream]\n",
      "Saving to: ‘nn_theta_check.npy’\n",
      "\n",
      "nn_theta_check.npy  100%[===================>] 155.43K   639KB/s    in 0.2s    \n",
      "\n",
      "2019-06-06 12:52:44 (639 KB/s) - ‘nn_theta_check.npy’ saved [159160/159160]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://github.com/DLR-SC/Neural-Network-Tutorial/raw/master/data/nn_theta_check.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-06 12:52:44--  https://raw.githubusercontent.com/DLR-SC/Neural-Network-Tutorial/master/mytools.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.112.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.112.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1022 [text/plain]\n",
      "Saving to: ‘mytools.py.1’\n",
      "\n",
      "mytools.py.1        100%[===================>]    1022  --.-KB/s    in 0s      \n",
      "\n",
      "2019-06-06 12:52:44 (56.3 MB/s) - ‘mytools.py.1’ saved [1022/1022]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/DLR-SC/Neural-Network-Tutorial/master/mytools.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Excercise#\n",
    "\n",
    "Now let's up our game and try some \"real machine learning\". In the following exercise we will:\n",
    " 1. Implement and check the loss function of the Neural Network\n",
    " 2. Classify images from a test data set and compute the accuracy.\n",
    " 3. Figure out, how test set accuracy and training set accuracy depend on the number of samples.\n",
    " 4. Try to improve the accuracy by changing the number of neurons in the hidden layer or by changing the regularization.\n",
    " \n",
    "## Aim and Tasks ##  \n",
    "We want to use a neural network to classify the MNIST dataset. This dataset consists of hand-written digits between 0 and 9, stored in $28\\times28$ pixel images. <br>\n",
    "The MNIST dataset is often called the \"Hello World\" of machine learning. \n",
    "\n",
    "![alt text](https://github.com/DLR-SC/Neural-Network-Tutorial/raw/master/images/mnist.png)\n",
    "<br>We want to implement a simple neural network (just like in the example before) with the following architecture: \n",
    " - The network has one input layer, one output layer and one hidden layer inbetween\n",
    " - The number of inputs $n_1$ equals the number of pixels (i.e. 28x28 = 784).\n",
    " - The number of hidden neurons ${n_2}$ can be chosen arbirarily, but for now we choose 25\n",
    " - The neural network has $K = 10$ output neurons, each of them representing one label. \n",
    "![alt text](https://github.com/DLR-SC/Neural-Network-Tutorial/raw/master/images/neural-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data ### \n",
    "First, we will load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import mnist\n",
    "\n",
    "imgs_train = mnist.train_images()\n",
    "y_train = mnist.train_labels()\n",
    "imgs_test = mnist.test_images()\n",
    "y_test = mnist.test_labels()\n",
    "\n",
    "print(imgs_train.shape)\n",
    "print(imgs_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire training data set consists of 60 000 images, and the testing data set of 10 000 images. <br>\n",
    "Let's see what the data looks like. Here is the first 8 images of the MNIST data set of hand-written numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "fig, axes = plt.subplots(1, 8)\n",
    "fig.set_size_inches(18, 8)\n",
    "\n",
    "# show the first 8 images of the test set\n",
    "for i in range(0, 8):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(imgs_train[i, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization and preparation ###\n",
    "\n",
    "As in the previous exercise, the data have to be normalized. Also, the 28 x 28 pixel 2D images are reshaped to a 1D input vectpor $X$ with 784 entries $x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_and_prepare(imgs):\n",
    "    # normalize between -0.5 ... 0.5\n",
    "    imgs_norm = np.array(imgs, dtype=float) / 255. - 0.5\n",
    "    # linearize the 2d image\n",
    "    return imgs_norm.reshape((imgs.shape[0], imgs.shape[1] * imgs.shape[2]))\n",
    "\n",
    "# we don't want to use the full data set, as our memory could run out\n",
    "n_train = 10000\n",
    "n_test = 10000\n",
    "\n",
    "X_train = normalize_and_prepare(imgs_train[0:n_train, :, :])\n",
    "X_test = normalize_and_prepare(imgs_test[0:n_test, :, :])\n",
    "\n",
    "y_train = y_train[0:n_train]\n",
    "y_test = y_test[0:n_test]\n",
    "\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation ##\n",
    "Now it's your turn. Let's implement and train the network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward ###\n",
    "__Excercise:__ First of all, implement the foward propagation, i.e. feed forward. For this, you will need the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1) $ h^{(0)} = x $ (= X_train)  \n",
    " 2) Add the row of 1s to $h^{(0)}$ to account for the constant bias  \n",
    " 3) $ z^{(1)} = w^{(0)} h^{(0)} $  \n",
    " 4) $ h^{(1)} = \\sigma(z^{(1)})$  \n",
    " 5) Add the row of 1s to $h^{(1)}$ to account for the constant bias  \n",
    " 6) $ z^{(2)} = w^{(1)} h^{(1)} $  \n",
    " 8) $ h^{(2)} = \\sigma(z^{(2)})$  \n",
    " 9) $y_{pred} = h^{(2)}$  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def propagate(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Propagates the input X through the neural network\n",
    "    :param theta_1: The parameters of hidden layer of the neural network\n",
    "    :param theta_2: The parameters of output layer of the neural network\n",
    "    :param X: The input data to be predicted\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # number of data items\n",
    "    m_samples = X.shape[0]\n",
    "    n_hidden_neurons = w_1.shape[1]\n",
    "    n_output_neurons = w_2.shape[1]\n",
    "    \n",
    "    #### start your code ####\n",
    "\n",
    "    # add the constant bias feature\n",
    "    h_0 = np.hstack((np.ones((m_samples, 1)), X))\n",
    "    \n",
    "    z_1 = np.dot(h_0, w_1)\n",
    "    h_1 = sigmoid(z_1)\n",
    "    # add the constant bias feature\n",
    "    h_1 = np.hstack((np.ones((m_samples, 1)), h_1))\n",
    "\n",
    "    z_2 = np.dot(h_1, w_2)\n",
    "    h_2 = sigmoid(z_2)\n",
    "    o = h_2\n",
    "\n",
    "    \n",
    "    ###### end your code #####\n",
    "    # assert o.shape == (m_samples, n_output_neurons)\n",
    "\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the loss function $L$ from $y_{pred}$ and $y_{true}=$ y_train. <br>\n",
    "We will use the loss function for logistic regression:\n",
    "$$\n",
    "L\\left(\\theta = (\\pmb{W^{(0)}},\\pmb{W^{(1)}}, \\pmb{b^{(0)}}, \\pmb{b^{(1)}})\\right) = - \\frac{1}{n} \\sum_{i=1}^n y_i \\:log\\left(o_{\\theta}(x_i)\\right) + (1-y_i)\\:log\\left(1-o_{\\theta}(x_i)\\right) + \\frac{\\lambda}{2n}\\sum_{j=1}^n\\theta_j^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(w, neurons_per_layer):\n",
    "    weight_layer = []\n",
    "    start = 0\n",
    "    for i in range(0, len(neurons_per_layer)-1):\n",
    "        size = (neurons_per_layer[i] + 1) * neurons_per_layer[i+1]\n",
    "        w_cur_layer = w[start: start+size].reshape((neurons_per_layer[i] + 1, neurons_per_layer[i+1]))\n",
    "        weight_layer.append(w_cur_layer)\n",
    "        start = start + size\n",
    "    \n",
    "    return weight_layer\n",
    "    \n",
    "import copy\n",
    "def nn_loss_function(w, X, y, lam, n_hidden_neurons, n_labels):\n",
    "    \"\"\"\n",
    "    :param theta: Parameters of the regressor\n",
    "    :param X: Input values (n_samples x n_features)\n",
    "    :param y: Ground truth labels for each sample of X\n",
    "    :param lam: Regularization parameter\n",
    "    :return: Cost value\n",
    "    \"\"\"\n",
    "\n",
    "    # number of data items\n",
    "    m_samples = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "   \n",
    "    w_1, w_2 = extract_weights(w, [n_features, n_hidden_neurons, n_labels])\n",
    "    \n",
    "    y_pred = propagate(X, w_1, w_2)\n",
    "    \n",
    "    #### start your code ####\n",
    "    # TODO: Compute the loss function of the log regression\n",
    "    cost = -y * np.log(y_pred) - (1. - y) * np.log(1. - y_pred)\n",
    "\n",
    "    # regularized cost function\n",
    "    L = 1. / m_samples * np.sum(cost) + lam / (2. * m_samples) * (np.sum(w_1[1:, :] ** 2) + np.sum(w_2[1:, :] ** 2))\n",
    "\n",
    "\n",
    "    ###### end your code #####\n",
    "\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy check ###\n",
    "Let's check the accuracy of the loss function. We load some pre-defined weights $w$ and compare the loss with a reference value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray, your loss function looks good\n"
     ]
    }
   ],
   "source": [
    "import mytools\n",
    "import numpy\n",
    "# this loads already theta values for all labels.\n",
    "# we want to check it however just for one label\n",
    "w_check = numpy.load('nn_theta_check.npy')\n",
    "\n",
    "expected_loss = nn_loss_function(w_check, X_train[0:5000],\n",
    "                                 mytools.encode_one_hot(y_train[0:5000], 10),\n",
    "                                                 0.1, 25, 10)\n",
    "\n",
    "# this value must be roughly 6.730543\n",
    "if np.abs(expected_loss - 6.730543) > 1e-4:\n",
    "    print(\"Oooops... please check your loss function\")\n",
    "else:\n",
    "    print(\"Hooray, your loss function looks good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training  ###\n",
    "\n",
    "If your loss function passes the accuracy tests, it is time to do the training!\n",
    "\n",
    "Do do symmetry breaking, we initialize the parameters $w$ with some small random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_layer_weights(n_input, n_output):\n",
    "    \"\"\"\n",
    "    Initialize theta randomly so that we break the symmetry while\n",
    "                training the neural network.\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 0.12\n",
    "    w = np.random.rand(n_input + 1, n_output) * eps * 2. - eps\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines our training procedure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import autograd\n",
    "def train(X, y, n_hidden_neurons, num_labels, regularization, max_iter):\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    # initialize parameters\n",
    "    w_1 = initial_layer_weights(n_features, n_hidden_neurons)\n",
    "    w_2 = initial_layer_weights(n_hidden_neurons, num_labels)\n",
    "\n",
    "    # we have to linearize then for the optimizer\n",
    "    w = np.hstack((w_1.flatten(), w_2.flatten()))\n",
    "\n",
    "    def cost_function(t):\n",
    "        return nn_loss_function(t, X, y, regularization, n_hidden_neurons, num_labels)\n",
    "\n",
    "    print(\"Training neural network... time to get a coffee\")\n",
    "\n",
    "    res = scipy.optimize.minimize(cost_function,\n",
    "                                  w, jac=autograd.grad(cost_function),\n",
    "                                  options={'disp': True, 'maxiter': max_iter}, method='CG')\n",
    "\n",
    "    # restore layer 1 and 2 parameters\n",
    "    return extract_weights(res.x, [n_features, n_hidden_neurons, num_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network... time to get a coffee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debusc/pytorch_env/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py:444: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return lambda g: g[idxs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.486321\n",
      "         Iterations: 1000\n",
      "         Function evaluations: 1392\n",
      "         Gradient evaluations: 1392\n"
     ]
    }
   ],
   "source": [
    "n_hidden_neurons = 25\n",
    "regularization = 2.25\n",
    "n_train_samples = 3000\n",
    "max_iter = 1000\n",
    "\n",
    "w_1, w_2 = train(X_train[0: n_train_samples, :],\n",
    "                         mytools.encode_one_hot(y_train[0: n_train_samples], 10),\n",
    "                         n_hidden_neurons, 10, regularization, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification  ###\n",
    "\n",
    "First we implement our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(X, w_1, w_2):\n",
    "    \"\"\"\n",
    "    Predicts the data using the logistic regression approach\n",
    "    :param X: The input data to be predicted\n",
    "    :param theta_1: The parameters of hidden layer of the neural network\n",
    "    :param theta_w: The parameters of output layer of the neural network\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    h = propagate(X, w_1, w_2)\n",
    "\n",
    "    # return index of maximum probability and probability\n",
    "    return np.argmax(h, axis=1), np.max(h, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets predict the first 8 images of the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 8)\n",
    "fig.set_size_inches(18, 8)\n",
    "\n",
    "# show the first 8 images of the test set\n",
    "for i in range(0, 8):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(imgs_test[i, :, :], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [7 2 1 0 4 1 4 9]\n"
     ]
    }
   ],
   "source": [
    "prediction, probabilty = predict_label(X_test[0:8, :], w_1, w_2)\n",
    "print (\"Prediction: \", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability:  [0.99606099 0.74325548 0.9711555  0.99364243 0.96650347 0.98751276\n",
      " 0.9572768  0.7411938 ]\n"
     ]
    }
   ],
   "source": [
    "print (\"Probability: \", probabilty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy ###\n",
    "\n",
    "Now, lets compute the accuracy of the classifier for the whole test set. A completely untrained classifier should roughly score 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the neural network on the test set: 91.58%\n"
     ]
    }
   ],
   "source": [
    "labels_predicted, probability = predict_label(X_test, w_1, w_2)\n",
    "accuracy = np.mean(np.array(labels_predicted == y_test, dtype=float))\n",
    "print (\"Accuracy of the neural network on the test set: %g%%\" % (accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further tasks## \n",
    "__Excercise:__\n",
    " - Investigate, how test accuracy and training accuracy depend on the test set size. Train the classifier with different n_train_samples and compute accuracies. What do you see?\n",
    " - Play around with the number of hidden layer neurons. What effect does it have?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
